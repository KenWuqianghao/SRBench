{
    "dataset": "712_chscase_geyser1",
    "algorithm": "GPGOMEARegressor",
    "params": {
        "caching": false,
        "classweights": false,
        "elitism": 1,
        "erc": true,
        "evaluations": 500000,
        "functions": "+_-_*_p/_plog_sqrt_sin_cos",
        "generations": -1,
        "gomea": true,
        "gomfos": "LT",
        "ims": false,
        "initmaxtreeheight": 4,
        "linearscaling": false,
        "maxsize": 1000,
        "maxtreeheight": 17,
        "parallel": false,
        "popsize": 1000,
        "prob": "symbreg",
        "reproduction": 0.0,
        "sbagx": 0.0,
        "sblibtype": false,
        "sbrdo": 0.0,
        "seed": -1,
        "silent": true,
        "subcross": 0.5,
        "submut": 0.5,
        "syntuniqinit": 1000,
        "time": 7200,
        "tournament": 4,
        "unifdepthvar": true
    },
    "random_state": 29910,
    "process_time": 8809.363564600999,
    "time_time": 8809.359194278717,
    "target_noise": 0.0,
    "feature_noise": 0.0,
    "model_size": 21,
    "symbolic_model": "((sqrt(cos(1.604000))*cos((3.541000p/x1)))+(plog((-3.784000*3.280000))*((x1*0.245000)p/(0.796000p/1.083000))))",
    "mse_train": 34.12424891001025,
    "mae_train": 4.6443330080982115,
    "r2_train": 0.7732952980804462,
    "mse_test": 44.870568977646144,
    "mae_test": 5.396212990445347,
    "r2_test": 0.7750845077787093
}